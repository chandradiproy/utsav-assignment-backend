# Hackathon Chatbot Backend

This project is a Flask-based chatbot backend that answers queries about a hackathon competition using data stored in MongoDB Atlas. The system uses LangChain to build conversational chains and leverages a Hugging Face model ("deepseek-ai/DeepSeek-R1-Distill-Qwen-32B") via the `HuggingFacePipeline` integration to generate responses.

## Table of Contents

- [Features](#features)
- [Requirements](#requirements)
- [Installation](#installation)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Endpoints](#api-endpoints)
- [Project Structure](#project-structure)
- [Notes](#notes)
- [License](#license)

## Features

- **MongoDB Atlas Integration:**  
  Stores hackathon data in three collections:
  - **teams:** Contains details about teams (team name, members, project, category, submission time).
  - **judges:** Stores information about judges (name, expertise).
  - **scores:** Holds individual evaluations linking teams and judges.
  
- **LLM-based Query Processing:**  
  Uses LangChain's HuggingFacePipeline integration to load the "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B" model, generating natural language responses to user queries.
  
- **Conversation Memory:**  
  Maintains multi-turn conversation context to improve response relevance.

- **Custom Prompt Template:**  
  Embeds the database schema and a snapshot of live hackathon data into the prompt for better context.

## Requirements

- Python 3.8+
- Flask
- LangChain and langchain_community (if applicable)
- Transformers, huggingface_hub
- PyMongo
- python-dotenv

## Installation

1. **Clone the Repository:**

   ```bash
   git clone https://github.com/chandradiproy/utsav-assignment-backend.git
   cd hackathon-chatbot-backend
    ```
2. **Create and Activate a Virtual Environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate   # On Windows: venv\Scripts\activate
    ```

3. **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4. **Configure Environment Variables:**
 Create a ``.env`` file in the root directory with your MongoDB Atlas connection string, e.g.:

    ```bash
    MONGO_URI="mongodb+srv://<username>:<password>@<cluster-url>/hackathon_db?retryWrites=true&w=majority"
    HF_API_KEY="hf_********************************"
    ```
## Usage
To run the flask app locally:
```bash
python app.py
```

## API Endpoints
#### ``/debug`` (GET)
- Description: Returns a list of collections and one sample document from each collection. Useful for verifying your database connection.
- Example Response:

    ```bash
    {
        "collections": ["teams", "judges", "scores"],
        "samples": {
            "teams": {"team_name": "AI Innovators", "members": [...], ...},
            "judges": {"name": "Judge A. Kim", "expertise": "Artificial Intelligence"},
            "scores": {"team_id": "...", "judge_id": "...", "final_score": 9, ...}
        }
    }

    ```
#### ``/query`` (POST)
- **Description**: Accepts a JSON payload with a ``"query"`` key (and optionally a ``"chat_history"`` key). It processes the query by including hackathon data context and returns an answer generated by the LLM.
- Example Request Body:
    ```bash
    {
    "query": "Who is the best team?",
    "chat_history": ""
    }
    ```
- Example Response

    ```bash
    {
    "query": "Who is the best team?",
    "chat_history": ""
    }
    ```
## Project Structure
```bash
hackathon-chatbot-backend/
├── README.md
├── requirements.txt
├── app.py
├── db.py
```

## Notes
- **Model Integration:**
This project uses the HuggingFacePipeline integration to load the "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B" model. Make sure you have a proper internet connection to download the model the first time.
- **Database Setup:**
Ensure you have created the required MongoDB collections (``teams``, ``judges``, and ``scores``) and inserted sample data.
- **Prompt Customization:**
The prompt template in app.py includes the hackathon schema and live data context. You can adjust this as needed.
